# ğŸ§  Cognitive Memory - PersistentnÃ­ pamÄ›Å¥ pro LLM

Biologicky inspirovanÃ½ systÃ©m dlouhodobÃ© pamÄ›ti pro velkÃ© jazykovÃ© modely. Implementuje dvouvrstvou pamÄ›Å¥ovou architekturu (STM/LTM) s 3D difuznÃ­mi terÃ©ny a RBF kernel operacemi.

> **Verze:** 2.0-beta  
> **Status:** âœ… PlnÄ› funkÄnÃ­ a validovÃ¡no  
> **PÅ¯vod:** BioCortexAI Framework  
> **Licence:** CC BY-NC 4.0

---

## ğŸ“– Obsah

- [Koncept a Inspirace](#-koncept-a-inspirace)
- [Architektura](#-architektura)
- [Instalace](#-instalace)
- [RychlÃ½ start](#-rychlÃ½-start)
- [Struktura sloÅ¾ky](#-struktura-sloÅ¾ky)
- [MatematickÃ½ popis](#-matematickÃ½-popis)
- [Konfigurace](#-konfigurace)
- [TestovÃ¡nÃ­](#-testovÃ¡nÃ­)
- [Citace](#-citace)
- [Podpora](#-podpora)

---

## ğŸ’¡ Koncept a Inspirace

### BiologickÃ¡ analogie

Cognitive Memory je inspirovÃ¡na biologickÃ½m pamÄ›Å¥ovÃ½m systÃ©mem:

| BiologickÃ¡ struktura | Analogie v systÃ©mu | Funkce |
|---------------------|-------------------|---------|
| **Hippocampus** | STM (16D) | RychlÃ© kÃ³dovÃ¡nÃ­, omezenÃ¡ kapacita |
| **Neokortex** | LTM (64D) | PomalÃ¡ konsolidace, dlouhodobÃ¡ retence |
| **SpÃ¡nek (SWS)** | Konsolidace | PÅ™enos vzpomÃ­nek ze STM do LTM |

**KlÃ­ÄovÃ© vlastnosti:**
- **Difuze**: Stopy se v Äase rozptylujÃ­ (LaplaceÅ¯v operÃ¡tor)
- **HomeostÃ¡za**: PomalÃ½ nÃ¡vrat k rovnovÃ¡Å¾nÃ©mu stavu  
- **Zlomy**: OpakovanÃ¡ aktivita vytvÃ¡Å™Ã­ "koleje", kterÃ© jsou citlivÄ›jÅ¡Ã­ k opÄ›tovnÃ© aktivaci
- **EmoÄnÃ­ zbarvenÃ­**: 4D emoÄnÃ­ vektor (dopamin, serotonin, kortizol, oxytocin)

---

## ğŸ—ï¸ Architektura

### DvouvrstvÃ½ systÃ©m

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         COGNITIVE MEMORY                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   LTM (64D)          â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤   STM (16D)          â”‚      â”‚
â”‚  â”‚   half-life ~1yr     â”‚  sleep  â”‚   half-life ~weeks   â”‚      â”‚
â”‚  â”‚                      â”‚         â”‚                      â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚      â”‚
â”‚  â”‚  â”‚ RBF Centers   â”‚   â”‚         â”‚  â”‚ RBF Centers   â”‚   â”‚      â”‚
â”‚  â”‚  â”‚ K: [N, 64]    â”‚   â”‚         â”‚  â”‚ K: [M, 16]    â”‚   â”‚      â”‚
â”‚  â”‚  â”‚ V: [N, 128]   â”‚   â”‚         â”‚  â”‚ V: [M, 128]   â”‚   â”‚      â”‚
â”‚  â”‚  â”‚ h: [N]        â”‚   â”‚         â”‚  â”‚ h: [M]        â”‚   â”‚      â”‚
â”‚  â”‚  â”‚ e: [N, 4]     â”‚   â”‚         â”‚  â”‚ e: [M, 4]     â”‚   â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚      â”‚
â”‚  â”‚         â†•             â”‚         â”‚         â†•             â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚      â”‚
â”‚  â”‚  â”‚ 3D Terrain    â”‚   â”‚         â”‚  â”‚ 3D Terrain    â”‚   â”‚      â”‚
â”‚  â”‚  â”‚ HÂ³: [48Â³]     â”‚   â”‚         â”‚  â”‚ HÂ³: [48Â³]     â”‚   â”‚      â”‚
â”‚  â”‚  â”‚ EÂ³: [48Â³, 4]  â”‚   â”‚         â”‚  â”‚ EÂ³: [48Â³, 4]  â”‚   â”‚      â”‚
â”‚  â”‚  â”‚ (diffusion)   â”‚   â”‚         â”‚  â”‚ (fast diff.)  â”‚   â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚            â†•                                  â†•                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              TransformerBlock Memory Attention            â”‚   â”‚
â”‚  â”‚  Y = X + SA(LN(X))                                        â”‚   â”‚
â”‚  â”‚  M = MemAttn(LN(Y))  â† TerrainPrior + RBF read            â”‚   â”‚
â”‚  â”‚  Y' = Y + g âŠ™ W_m M                                       â”‚   â”‚
â”‚  â”‚  X_out = Y' + MLP(LN(Y'))                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DatovÃ© struktury

#### PamÄ›Å¥ovÃ¡ centra (RBF Kernel-Poles)

| Komponenta | RozmÄ›r | Popis |
|-----------|--------|-------|
| **K** | R^64 (LTM) / R^16 (STM) | NormalizovanÃ½ klÃ­Ä (sÃ©mantickÃ¡ pozice) |
| **V** | R^128 | Hodnota (co vybavit) |
| **h** | R^+ | Intenzita/hloubka stopy (GS) |
| **e** | R^4 | EmoÄnÃ­ vektor (dopamin, serotonin, kortizol, oxytocin) |
| **usage** | Z^+ | ÄŒÃ­taÄ pouÅ¾itÃ­ (pro pruning) |
| **age** | Z^+ | StÃ¡Å™Ã­ centra |

#### 3D terÃ©ny

```
RozliÅ¡enÃ­: 48 Ã— 48 Ã— 48 voxelÅ¯
HÂ³ âˆˆ R^(48Ã—48Ã—48)       # Intenzita (GS/"pÄ›na")
EÂ³ âˆˆ R^(48Ã—48Ã—48Ã—4)     # EmoÄnÃ­ stopa (4 hormony)
```

**Fyzika terÃ©nu:**
- Difuze: LaplaceÅ¯v operÃ¡tor (6-sousedÅ¯)
- HomeostÃ¡za: ExponenciÃ¡lnÃ­ decay
- Projekce: 64D â†’ 3D pÅ™es lineÃ¡rnÃ­ vrstvu + tanh

---

## ğŸ“¦ Instalace

### ZÃ¡vislosti

```bash
pip install torch>=2.0.0
pip install numpy>=1.20.0
pip install scipy>=1.7.0
```

### Integrace do projektu

```python
from cognitive_memory import CognitiveMemorySystem, MemoryConfig

# VytvoÅ™ konfiguraci
config = MemoryConfig(
    d_model=256,              # Dimenze transformeru
    n_ltm_centers=1024,       # PoÄet LTM center
    ltm_leak=3.8e-5,          # Leak pro roÄnÃ­ provoz
)

# Inicializuj systÃ©m
memory = CognitiveMemorySystem(config, device="cuda")
```

---

## ğŸš€ RychlÃ½ start

### ZÃ¡kladnÃ­ pouÅ¾itÃ­

```python
import torch
from cognitive_memory import CognitiveMemorySystem, MemoryConfig

# 1. VytvoÅ™ pamÄ›Å¥ovÃ½ systÃ©m
config = MemoryConfig()
memory = CognitiveMemorySystem(config, device="cpu")

# 2. ÄŒtenÃ­ z pamÄ›ti (bÄ›hem inference)
hidden_states = torch.randn(1, 32, 256)  # [B, T, D]

# Memory Attention (pro Transformer vrstvu)
memory_context, emotions, gate = memory.read(
    hidden_states,
    layer_idx=7  # Jen hornÃ­ vrstvy
)

# 3. ZÃ¡pis do pamÄ›ti (po generovÃ¡nÃ­)
segment_states = torch.randn(5, 256)  # [N_segments, D]
current_emotions = torch.randn(5, 4)  # [N_segments, 4]

memory.write(
    segment_states=segment_states,
    emotions=current_emotions,
    surprise=0.3  # PredikÄnÃ­ chyba (volitelnÄ›)
)

# 4. Konsolidace (automatickÃ¡ pÅ™i dosaÅ¾enÃ­ prahu)
if memory.should_consolidate():
    stats = memory.consolidate()
    print(f"KonsolidovÃ¡no {stats['consolidated_centers']} vzpomÃ­nek")

# 5. UloÅ¾enÃ­/naÄtenÃ­
memory.save("memory_state.pt")
memory = CognitiveMemorySystem.load("memory_state.pt", device="cpu")
```

### Integrace do Transformer vrstvy

```python
import torch.nn as nn
from cognitive_memory import MemoryBlock, MemoryConfig

class TransformerBlockWithMemory(nn.Module):
    def __init__(self, d_model, config: MemoryConfig):
        super().__init__()
        self.ln1 = nn.LayerNorm(d_model)
        self.attn = Attention(...)  # StandardnÃ­ self-attention
        
        # Memory Attention
        self.ln_memory = nn.LayerNorm(d_model)
        self.memory_block = MemoryBlock(config)
        
        self.ln2 = nn.LayerNorm(d_model)
        self.ffn = FeedForward(...)
    
    def forward(self, x, memory_state):
        # 1. Self-Attention
        y = x + self.attn(self.ln1(x))
        
        # 2. Memory Attention (s gate)
        if memory_state is not None:
            m, emotions, gate = self.memory_block(
                self.ln_memory(y), 
                memory_state
            )
            y = y + gate * m  # Gated residual
        
        # 3. Feed-Forward
        out = y + self.ffn(self.ln2(y), emotions)
        
        return out
```

---

## ğŸ“‚ Struktura sloÅ¾ky

```
cognitive_memory/
â”œâ”€â”€ __init__.py                # Public API
â”œâ”€â”€ config.py                  # Konfigurace (MemoryConfig)
â”œâ”€â”€ memory_centers.py          # RBF kernel centra (LTM/STM)
â”œâ”€â”€ terrain_3d.py              # 3D difuznÃ­ terÃ©ny
â”œâ”€â”€ memory_block.py            # Memory Attention modul
â”œâ”€â”€ memory_attention.py        # Attention mechanismus
â”œâ”€â”€ terrain_prior.py           # TerrainPrior (3Dâ†’64D bias)
â”œâ”€â”€ writer.py                  # ZÃ¡pis segmentÅ¯
â”œâ”€â”€ consolidation.py           # Sleep konsolidace (STMâ†’LTM)
â”œâ”€â”€ projections.py             # Projekce (64Dâ†”3D, 16Dâ†’64D)
â”œâ”€â”€ persistence.py             # UklÃ¡dÃ¡nÃ­/naÄÃ­tÃ¡nÃ­ stavu
â””â”€â”€ README.md                  # Tato dokumentace
```

### Popis modulÅ¯

| Modul | Funkce |
|-------|--------|
| `config.py` | KonfiguraÄnÃ­ tÅ™Ã­da s koeficienty pro roÄnÃ­ provoz |
| `memory_centers.py` | RBF kernel operace (ÄtenÃ­/zÃ¡pis), homeostÃ¡za, merge/prune |
| `terrain_3d.py` | 3D grid s difuzÃ­ (Laplace), splat zÃ¡pis, sampling |
| `memory_block.py` | KompletnÃ­ Memory Attention + Gate pro Transformer |
| `terrain_prior.py` | 3Dâ†’64D posun dotazu, gate prior z terÃ©nu |
| `writer.py` | Segmentace, vÃ½poÄet sÃ­ly zÃ¡pisu (novost, surprise, emoce) |
| `consolidation.py` | Ãšnava, konsolidace STMâ†’LTM, normalizace |
| `projections.py` | LineÃ¡rnÃ­ projekce (64Dâ†’3D, 16Dâ†’64D) |
| `persistence.py` | UloÅ¾enÃ­/naÄtenÃ­ kompletnÃ­ho stavu pamÄ›ti |

---

## ğŸ“ MatematickÃ½ popis

### 1. ÄŒtenÃ­ z pamÄ›ti (RBF Kernel Retrieval)

#### 1.1 TerrainPrior (3Dâ†’64D bias)

Pro dotaz `q âˆˆ R^64`:

```
z = tanh(W_c @ q + b_c)  âˆˆ [-1,1]Â³    # Projekce do 3D
p_H = sample(HÂ³, z)  âˆˆ R              # Sampling intenzity
p_E = sample(EÂ³, z)  âˆˆ R^4            # Sampling emocÃ­

g_prior = Ïƒ(a_H * p_H + a_E^T @ p_E + b_g)  # Gate prior

qÌƒ = norm(q + Î²_q * R([p_H; p_E]))    # Posun dotazu
```

**ÃšÄel:** TerÃ©n Å™Ã­kÃ¡ "tady jsi uÅ¾ byl" â†’ otevÅ™e gate a posune dotaz

#### 1.2 RBF Kernel ÄtenÃ­

Pro kaÅ¾dÃ© centrum `i`:

```
w_i = exp(-||qÌƒ - K_i||Â² / 2ÏƒÂ²)       # RBF kernel

Ï€_i = softmax_i(log(Îµ + h_i) + log(w_i))  # Intenzita posiluje vÃ¡hy

r_V = Î£ Ï€_i * V_i  âˆˆ R^d_v            # ÄŒtenÃ© hodnoty
r_E = Î£ Ï€_i * e_i  âˆˆ R^4              # ÄŒtenÃ© emoce
```

#### 1.3 Gate (finÃ¡lnÃ­ rozhodnutÃ­)

```
g = Ïƒ(W_g @ [x; r_V] + u * g_prior)   # Kombinace obsahu + prior

x_out = x + g âŠ™ W_m @ r_V             # Gated residual
```

### 2. ZÃ¡pis do pamÄ›ti

#### 2.1 SÃ­la zÃ¡pisu (adaptivnÃ­)

Pro segment `s`:

```
Ï‰_s = Î·â‚€ * Ïƒ(c_n * novelty + c_Î´ * surprise + c_a * emotion_salience + b_Ï‰)
```

Kde:
- **novelty**: `1 - max(sim(k_s, K_i))`
- **surprise**: PredikÄnÃ­ chyba (entropie, KL divergence)
- **emotion_salience**: `||Îµ_s||` (norma emocÃ­)

#### 2.2 RBF zÃ¡pis do center

```
wÌ„_i = normalize(exp(-||k_s - K_i||Â² / 2Ïƒ_wÂ²))  # RBF vÃ¡hy

h_i â† h_i + Ï‰_s * wÌ„_i                          # Update intenzity
V_i â† V_i + Î±_V * Ï‰_s * wÌ„_i * (v_s - V_i)      # EMA hodnot
e_i â† e_i + Î±_E * Ï‰_s * wÌ„_i * (Îµ_s - e_i)      # EMA emocÃ­
```

**PÅ™idÃ¡nÃ­ novÃ©ho centra:**
```
Pokud max(wÌ„_i) < Ï„_new:
    K_new = k_s
    V_new = v_s
    h_new = Ï‰_s
    e_new = Îµ_s
```

#### 2.3 ZÃ¡pis do 3D terÃ©nu (splat)

```
z_s = tanh(W_c @ k_s)  âˆˆ [-1,1]Â³

Î”HÂ³(u) = Ï‰_s * exp(-||u - z_s||Â² / 2Ïƒâ‚ƒÂ²)
Î”EÂ³(u) = Ï‰_s * exp(-||u - z_s||Â² / 2Ïƒâ‚ƒÂ²) * Îµ_s

HÂ³ â† HÂ³ + Î·â‚ƒ * Î”HÂ³
EÂ³ â† EÂ³ + Î·â‚ƒ * Î”EÂ³
```

### 3. Difuze a homeostÃ¡za (kaÅ¾dÃ½ krok)

#### 3.1 3D terÃ©n (pÄ›na)

LaplaceÅ¯v operÃ¡tor (6-sousedÅ¯):

```
âˆ‡Â²HÂ³(i,j,k) = Î£ (HÂ³(neighbors) - HÂ³(i,j,k))

HÂ³ â† (1 - Î»â‚ƒ) * HÂ³ + Î±_H * âˆ‡Â²HÂ³    # Difuze + decay
EÂ³ â† (1 - Î»â‚ƒ) * EÂ³ + Î±_E * âˆ‡Â²EÂ³
```

#### 3.2 Centra (homeostÃ¡za)

```
h_i â† (1 - Î»_64) * h_i                   # Decay intenzity
V_i â† (1 - Î»_64^V) * V_i                 # Decay hodnot
e_i â† (1 - Î»_64^E) * e_i + Î»_64^E * 1    # NÃ¡vrat k neutrÃ¡lnÃ­ (1.0)
```

### 4. Konsolidace (spÃ¡nek)

#### 4.1 Ãšnava

```
F â† (1 - Î»_F) * F + Î£ Ï‰_s^stm

Pokud F > Î˜ â†’ spÃ¡nek
```

#### 4.2 PÅ™enos STM â†’ LTM

```
# Vyber top-M STM center podle h_i^s
C = TopM(h^s)

Pro kaÅ¾dÃ© i âˆˆ C:
    k^64 = norm(U @ K_i^s)               # 16D â†’ 64D projekce
    Ï‰_ltm = Îº * h_i^s                    # SnÃ­Å¾enÃ¡ sÃ­la
    
    LTM.write(k^64, V_i^s, e_i^s, Ï‰_ltm)  # ZÃ¡pis do LTM
```

#### 4.3 3D terÃ©n: STM â†’ LTM

```
H_LTMÂ³ â† H_LTMÂ³ + Î¾_H * blur(H_STMÂ³)
E_LTMÂ³ â† E_LTMÂ³ + Î¾_E * blur(E_STMÂ³)
```

#### 4.4 Normalizace STM (ne vymazÃ¡nÃ­!)

```
h^s â† log(1 + h^s)                       # Logaritmizace
V^s â† V^s / (1 + ||V^s|| / c_V)          # Saturace
e^s â† tanh(e^s)                          # Clipping

F â† Ï_F * F                              # Reset Ãºnavy
```

### 5. SprÃ¡va kapacity

#### 5.1 Merge podobnÃ½ch center

```
Pokud sim(K_i, K_j) > Ï„_merge:
    h_new = h_i + h_j
    K_new = norm((h_i * K_i + h_j * K_j) / h_new)
    V_new = (h_i * V_i + h_j * V_j) / h_new
    e_new = (h_i * e_i + h_j * e_j) / h_new
```

#### 5.2 Prune slabÃ½ch center

```
Odstranit centrum i pokud:
    h_i < Ï„_h  AND
    usage_i < Ï„_u  AND
    age_i > Ï„_age
```

---

## âš™ï¸ Konfigurace

### Koeficienty pro roÄnÃ­ provoz

VÅ¡echny defaultnÃ­ hodnoty jsou kalibrovÃ¡ny pro **~50 interakcÃ­/den** = **~18 250 krokÅ¯/rok**.

#### LTM (64D) - PoloÄas ~1 rok

```python
ltm_leak = 3.8e-5           # Î»_64 - extrÃ©mnÄ› pomalÃ½ decay
ltm_alpha_value = 0.03      # Î±_V - update rychlost hodnot
ltm_alpha_emotion = 0.01    # Î±_E - update rychlost emocÃ­
ltm_sigma_read = 0.5        # Ïƒ pro RBF ÄtenÃ­ (0.3-0.7)
ltm_sigma_write = 0.15      # Ïƒ pro RBF zÃ¡pis (AGRESIVNÃ: ostrÃ© stopy)
ltm_new_center_threshold = 0.8  # Ï„_new (AGRESIVNÃ: jen pÅ™i >80% shodÄ›)
```

**VÃ½znam:**
- **MalÃ½ leak** â†’ vzpomÃ­nky vydrÅ¾Ã­ ~1 rok
- **MalÃ½ alpha** â†’ hodnoty se mÄ›nÃ­ pomalu (stabilita)
- **MalÃ½ sigma_write** â†’ ostrÃ©, lokalizovanÃ© stopy
- **VysokÃ½ threshold** â†’ ÄastÄ›ji vytvÃ¡Å™Ã­ novÃ¡ centra (granularita)

#### STM (16D) - PoloÄas dny aÅ¾ tÃ½dny

```python
stm_leak = 5e-3             # Î»_stm - rychlejÅ¡Ã­ decay
stm_alpha_value = 0.1       # Î±_V^s - rychlejÅ¡Ã­ update
stm_sigma_write = 0.2       # Ïƒ_w - ostÅ™ejÅ¡Ã­ neÅ¾ LTM
```

#### 3D terÃ©ny

```python
# LTM terÃ©n (pomalÃ½)
terrain_ltm_lambda = 5e-5   # Î»_3 - decay
terrain_ltm_alpha_h = 0.002 # Î±_H - difuze intenzity
terrain_ltm_alpha_e = 0.001 # Î±_E - difuze emocÃ­

# STM terÃ©n (rychlÃ½)
terrain_stm_alpha_h = 0.02  # 10Ã— rychlejÅ¡Ã­ difuze
```

#### Konsolidace

```python
fatigue_threshold = 5.0     # Î˜ - prÃ¡h pro spÃ¡nek (AGRESIVNÃ: 5.0)
consolidation_kappa = 0.8   # Îº - pÅ™epoÄet intenzity (AGRESIVNÃ: 0.8)
normalization_rho_f = 0.2   # Ï_F - reset Ãºnavy (zachovÃ¡ 20%)
```

### LadÄ›nÃ­ koeficientÅ¯

#### Pro vÃ­ce granularity (vÃ­ce center):

```python
config.ltm_new_center_threshold = 0.9    # VyÅ¡Å¡Ã­ â†’ ÄastÄ›jÅ¡Ã­ novÃ¡ centra
config.ltm_sigma_write = 0.1             # UÅ¾Å¡Ã­ â†’ ostÅ™ejÅ¡Ã­ stopy
```

#### Pro stabilnÄ›jÅ¡Ã­ pamÄ›Å¥ (mÃ©nÄ› zmÄ›n):

```python
config.ltm_alpha_value = 0.01            # PomalejÅ¡Ã­ update
config.write_strength_base = 0.1         # SlabÅ¡Ã­ zÃ¡pis
```

#### Pro rychlejÅ¡Ã­ zapomÃ­nÃ¡nÃ­:

```python
config.ltm_leak = 1e-4                   # PoloÄas ~3 mÄ›sÃ­ce
config.terrain_ltm_lambda = 1e-4         # RychlejÅ¡Ã­ decay terÃ©nu
```

---

## ğŸ§ª TestovÃ¡nÃ­

### ValidaÄnÃ­ framework

V sloÅ¾ce `../memory-tests/` najdeÅ¡ kompletnÃ­ test suite:

```bash
# ZÃ¡kladnÃ­ testy (3 sec)
python memory-tests/test_memory_fundamentals.py

# KvalitativnÃ­ testy (6 sec)
python memory-tests/memory_quality_test.py

# Stress test (~5 min, 9000 interakcÃ­ = ~6 mÄ›sÃ­cÅ¯)
python memory-tests/stress_test_memory.py

# KompletnÃ­ suite s vizualizacemi (~10 min)
python memory-tests/run_full_memory_suite.py
```

### DostupnÃ© testy

| Test | ÃšÄel | VÃ½stup |
|------|------|--------|
| `test_memory_fundamentals.py` | Write/Read, retention, kapacita | PASS/FAIL |
| `memory_quality_test.py` | Interference, konsolidace | Metriky |
| `stress_test_memory.py` | ZÃ¡tÄ›Å¾ovÃ½ test (9000 krokÅ¯) | JSON + CSV |
| `ablation_study.py` | AblaÄnÃ­ studie (4 konfigurace) | SrovnÃ¡nÃ­ |
| `visualize_*.py` | Vizualizace topologie, difuze | PNG grafy |

### ValidovanÃ© metriky (2026-01-14)

#### Stress Test (9000 interakcÃ­)

| Metrika | Hodnota | Status |
|---------|---------|--------|
| LTM Active Centers | **459** | âœ… VynikajÃ­cÃ­ granularita |
| STM Active Centers | 141 | âœ… OK |
| Consolidation Events | 65 | âœ… PravidelnÃ¡ konsolidace |
| h_max (intenzita) | 42.0 | âœ… OK |

#### FundamentÃ¡lnÃ­ testy

| Test | VÃ½sledek |
|------|----------|
| Direct Write/Read | âœ… 100% similarity |
| Retention (1000 krokÅ¯) | âœ… 100% |
| Capacity | âœ… 50 center |
| Similarity Retrieval | âœ… 100% accuracy |

#### Rekonstrukce vzpomÃ­nek

| Metrika | Hodnota | Interpretace |
|---------|---------|--------------|
| Self-Reconstruction | **0.92** | B grade - Velmi dobrÃ¡ |
| StÃ¡rnutÃ­ (Q4-Q1) | +0.20 | D grade - StarÃ© vzpomÃ­nky degradujÃ­ |
| Self-Weight | 0.38 | Retrieval je "mÄ›kkÃ½" (RBF) |

---

## ğŸ“š Citace

Pokud pouÅ¾Ã­vÃ¡Å¡ Cognitive Memory ve svÃ© prÃ¡ci, prosÃ­m cituj:

```bibtex
@software{cognitive_memory_2026,
  author = {Seidl, Michal},
  title = {Cognitive Memory: Biologicky inspirovanÃ½ systÃ©m persistentnÃ­ pamÄ›ti pro LLM},
  year = {2026},
  publisher = {OpenTechLab Jablonec nad Nisou},
  version = {2.0-beta},
  url = {https://github.com/OpenTechLab/cognitive-memory}
}
```

### TeoretickÃ½ zÃ¡klad

SystÃ©m vychÃ¡zÃ­ z tÄ›chto konceptÅ¯:

- **Atkinson-Shiffrin model** (1968): RozdÄ›lenÃ­ STM/LTM
- **Complementary Learning Systems** (McClelland, McNaughton, O'Reilly, 1995): Hippocampus-neocortex interakce
- **Memory consolidation** (Sleep-wake cycle)
- **RBF networks** (Radial Basis Function kernels)
- **Reaction-diffusion systems** (Turing, 1952): Difuze v prostoru

---

## ğŸ› ï¸ PokroÄilÃ© pouÅ¾itÃ­

### PÅ™izpÅ¯sobenÃ­ projekcÃ­

```python
from cognitive_memory.projections import TerrainProjection

# VlastnÃ­ 64D â†’ 3D projekce (napÅ™. autoenkodÃ©r)
class CustomProjection(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 3),
            nn.Tanh()
        )
    
    def forward(self, x):
        return self.encoder(x)

# PouÅ¾itÃ­
config.terrain_projection = CustomProjection()
```

### MonitorovÃ¡nÃ­ stavu

```python
# ZÃ­skej detailnÃ­ statistiky
ltm_stats = memory.ltm_centers.get_stats()
print(f"LTM centra: {ltm_stats['n_active']}")
print(f"PrÅ¯mÄ›rnÃ¡ intenzita: {ltm_stats['h_mean']:.3f}")
print(f"Max intenzita: {ltm_stats['h_max']:.3f}")

# TerÃ©nnÃ­ statistiky
terrain_stats = memory.ltm_terrain.get_stats()
print(f"CelkovÃ¡ energie: {terrain_stats['total_energy']:.3f}")

# ÃšroveÅˆ Ãºnavy
fatigue = memory.consolidator.get_fatigue_level()
print(f"Ãšnava: {fatigue * 100:.1f}%")
```

### Export vizualizacÃ­

```python
# Export 3D terÃ©n jako numpy array
terrain_h = memory.ltm_terrain.H.cpu().numpy()  # [48, 48, 48]
terrain_e = memory.ltm_terrain.E.cpu().numpy()  # [48, 48, 48, 4]

# PouÅ¾ij matplotlib/plotly pro vizualizaci
import matplotlib.pyplot as plt
plt.imshow(terrain_h[:, :, 24], cmap='viridis')
plt.title("LTM Terrain - Central Slice")
plt.colorbar()
plt.savefig("terrain_slice.png")
```

---

## ğŸ› Troubleshooting

| ProblÃ©m | MoÅ¾nÃ¡ pÅ™Ã­Äina | Å˜eÅ¡enÃ­ |
|---------|---------------|--------|
| Memory Error pÅ™i inicializaci | PÅ™Ã­liÅ¡ velkÃ½ 3D grid | SnÃ­Å¾it `terrain_resolution` na 32 nebo 24 |
| LTM se rychle plnÃ­ | PÅ™Ã­liÅ¡ agresivnÃ­ vytvÃ¡Å™enÃ­ center | SnÃ­Å¾it `ltm_new_center_threshold` na 0.5 |
| Å½Ã¡dnÃ© konsolidace | NÃ­zkÃ¡ aktivita STM | SnÃ­Å¾it `fatigue_threshold` na 3.0 |
| PÅ™Ã­liÅ¡ pomalÃ© ÄtenÃ­ | VelkÃ½ `ltm_top_k_read` | SnÃ­Å¾it na 16 nebo 8 |
| Gate vÅ¾dy zavÅ™enÃ½ | PÅ™Ã­liÅ¡ zÃ¡pornÃ½ `gate_bias` | ZvÃ½Å¡it na -1.5 |
| Hodnoty "explodujÃ­" | PÅ™Ã­liÅ¡ silnÃ½ zÃ¡pis | SnÃ­Å¾it `write_strength_base` na 0.1 |

### Debug mÃ³d

```python
# Zapni verbose logging
import logging
logging.basicConfig(level=logging.DEBUG)

# Kontrola NaN
assert not torch.isnan(memory.ltm_centers.h).any(), "NaN v intenzitÃ¡ch!"
assert not torch.isnan(memory.ltm_terrain.H).any(), "NaN v terÃ©nu!"
```

---

## ğŸ“– DalÅ¡Ã­ dokumentace

- **`BioCortexAI_Documentation_EN.md`**: KompletnÃ­ vÄ›deckÃ¡ dokumentace
- **`plan.md`**: PÅ¯vodnÃ­ matematickÃ½ nÃ¡vrh (developer notes)
- **`memory-tests/README.md`**: TestovacÃ­ framework a benchmark

---

## ğŸ¤ Podpora

### Issues

Pokud narazÃ­Å¡ na problÃ©m:
1. OvÄ›Å™, Å¾e pouÅ¾Ã­vÃ¡Å¡ nejnovÄ›jÅ¡Ã­ verzi
2. Zkontroluj [Troubleshooting](#-troubleshooting)
3. OtevÅ™i issue s:
   - VerzÃ­ Python a PyTorch
   - MinimÃ¡lnÃ­m reprodukÄnÃ­m pÅ™Ã­kladem
   - ChybovÃ½m hlÃ¡Å¡enÃ­m

### Kontakt

- **Email**: vyvoj@opentechlab.cz
- **Web**: [www.opentechlab.cz](https://www.opentechlab.cz)
- **Projekt**: BioCortexAI

---

## ğŸ“„ Licence

**CC BY-NC 4.0** (Creative Commons Attribution-NonCommercial 4.0)

âœ… **Povoleno:**
- PouÅ¾itÃ­ pro vÃ½zkum a vzdÄ›lÃ¡vÃ¡nÃ­
- Modifikace a distribuce (s uvedenÃ­m autora)
- SoukromÃ© experimenty

âŒ **ZakÃ¡zÃ¡no:**
- KomerÄnÃ­ vyuÅ¾itÃ­ bez licence
- Patent claims

Pro komerÄnÃ­ licenci kontaktujte: opentechlab@opentechlab.cz

---

**Framework:** BioCortexAI v2.0-beta  
**Author:** Michal Seidl, OpenTechLab Jablonec nad Nisou s.r.o.  
**Status:** âœ… Production-ready
