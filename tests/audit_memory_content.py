import torch
import torch.nn.functional as F
from pathlib import Path
import sys
import numpy as np
import matplotlib.pyplot as plt

# Importy z projektu
sys.path.insert(0, str(Path(__file__).parent.parent))
from cognitive_memory.memory_centers import MemoryCenters

def audit_memory():
    print('='*60)
    print('ğŸ•µï¸ AUDIT OBSAHU PAMÄšTI (RETRIEVAL TEST)')
    print('='*60)
    
    # 1. NaÄÃ­st snapshot
    snapshot_dirs = list(Path("stress_test_results").glob("RealisticMixed_step_*/memory.pt"))
    if not snapshot_dirs:
        print("âŒ Å½Ã¡dnÃ½ snapshot.")
        return
    latest = max(snapshot_dirs, key=lambda p: p.stat().st_mtime)
    print(f"ğŸ“‚ NaÄÃ­tÃ¡m snapshot: {latest.name}")
    
    state = torch.load(str(latest), map_location='cpu', weights_only=False)
    
    if 'ltm_centers' not in state:
        print("âŒ ChybÃ­ LTM centers.")
        return
        
    # Rekonstrukce center
    centers_state = state['ltm_centers']
    # PotÅ™ebujeme vytvoÅ™it instanci pro pouÅ¾itÃ­ metody read()
    # ZÃ­skÃ¡me parametry ze state dict (odhadem)
    n_centers = centers_state['K'].shape[0]
    d_key = centers_state['K'].shape[1]
    d_value = centers_state['V'].shape[1]
    
    mc = MemoryCenters(
        n_centers=n_centers,
        d_key=d_key,
        d_value=d_value,
        sigma_read=0.3, # PouÅ¾ijeme standardnÃ­ hodnotu
        device='cpu'
    )
    
    # Load state manually
    mc.K.copy_(centers_state['K'])
    mc.V.copy_(centers_state['V'])
    
    # Emoce: v MemoryCenters je to 'e', v Terrain3D 'E'
    # Ve snapshotu center by to mÄ›lo bÃ½t 'e'
    if 'e' in centers_state:
        mc.e.copy_(centers_state['e'])
    elif 'E' in centers_state: # Backward compatibility
        mc.e.copy_(centers_state['E'])
        
    if 'h' in centers_state:
        mc.h.copy_(centers_state['h'])
    elif 'H' in centers_state:
        mc.h.copy_(centers_state['H'])
        
    mc.active.copy_(centers_state['active'])
    mc.usage.copy_(centers_state['usage'])
    
    n_active = mc.get_n_active()
    print(f"âœ… PamÄ›Å¥ naÄtena: {n_active} aktivnÃ­ch center")
    
    if n_active < 2:
        print("âš ï¸ PÅ™Ã­liÅ¡ mÃ¡lo center pro test diskriminace.")
        return

    # 2. Test diskriminace (RozliÅ¡itelnost)
    # Vezmeme existujÃ­cÃ­ klÃ­Äe z aktivnÃ­ch center a zkusÃ­me je vybavit
    active_indices = torch.where(mc.active)[0]
    
    # Vybereme 5 nÃ¡hodnÃ½ch center jako "Queries"
    sample_indices = active_indices[torch.randperm(len(active_indices))[:5]]
    
    print("\nğŸ§ª TEST DISKRIMINACE (Query = Key existujÃ­cÃ­ho centra):")
    print(f"{'Query ID':<10} | {'Found Match':<10} | {'Confidence':<10} | {'Similarity':<10} | {'Status'}")
    print("-" * 65)
    
    distinct_values = []
    
    for idx in sample_indices:
        # Dotaz je pÅ™Ã­mo klÃ­Ä centra (ideÃ¡lnÃ­ pÅ™Ã­pad)
        query_key = mc.K[idx].view(1, 1, d_key)
        target_value = mc.V[idx]
        
        # Read
        # read vracÃ­: values, emotions, weights, indices
        r_V, r_E, weights, _ = mc.read(query_key, top_k=4)
        
        retrieved_val = r_V.squeeze()
        confidence = weights.sum().item()
        
        # SpoÄÃ­tat podobnost s oÄekÃ¡vanou hodnotou (self)
        sim = F.cosine_similarity(retrieved_val.unsqueeze(0), target_value.unsqueeze(0)).item()
        
        distinct_values.append(retrieved_val)
        
        status = "âœ… OK" if sim > 0.9 else "âš ï¸ Weak" if sim > 0.5 else "âŒ Fail"
        
        print(f"{idx.item():<10} | {weights[0,0,0].item():.4f}     | {confidence:.4f}     | {sim:.4f}     | {status}")

    # 3. KÅ™Ã­Å¾ovÃ¡ podobnost (Cross-Talk)
    # Zkontrolujeme, zda jsou "vybavenÃ© hodnoty" odliÅ¡nÃ©
    print("\nğŸ” KÅ˜ÃÅ½OVÃ KONTROLA (Jsou vybavenÃ© vzpomÃ­nky rÅ¯znÃ©?):")
    import itertools
    
    tensor_stack = torch.stack(distinct_values)
    # Matice podobnosti [5, 5]
    cross_sim = torch.mm(tensor_stack, tensor_stack.t())
    
    # PrÅ¯mÄ›rnÃ¡ podobnost mimo diagonÃ¡lu
    mask = ~torch.eye(5, dtype=bool)
    avg_cross_sim = cross_sim[mask].mean().item()
    
    print(f"PrÅ¯mÄ›rnÃ¡ podobnost mezi RÅ®ZNÃMI vzpomÃ­nkami: {avg_cross_sim:.4f}")
    
    if avg_cross_sim > 0.8:
        print("âŒ PROBLÃ‰M: PamÄ›Å¥ vracÃ­ velmi podobnÃ© hodnoty pro rÅ¯znÃ© dotazy (Mode Collapse).")
    elif avg_cross_sim < 0.5:
        print("âœ… ÃšSPÄšCH: PamÄ›Å¥ pro rÅ¯znÃ© klÃ­Äe vracÃ­ RÅ®ZNÃ‰ hodnoty.")
    else:
        print("âš ï¸ VAROVÃNÃ: VzpomÃ­nky jsou si ÄÃ¡steÄnÄ› podobnÃ© (moÅ¾nÃ¡ sdÃ­lenÃ© tÃ©ma).")

    # UloÅ¾it heatmapu
    plt.figure()
    plt.imshow(cross_sim.detach().numpy(), cmap='viridis', vmin=0, vmax=1)
    plt.colorbar(label='Cosine Similarity')
    plt.title('Cross-Similarity of Retrieved Memories')
    plt.savefig('memory_discrimination_audit.png')
    print("Graph saved: memory_discrimination_audit.png")

if __name__ == "__main__":
    audit_memory()
