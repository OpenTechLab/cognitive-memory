# memory_quality_test.py
"""
KVALITATIVN√ç TESTY COGNITIVE MEMORY

Mƒõ≈ô√≠ skuteƒçnou U≈ΩITEƒåNOST pamƒõti:
1. RETENTION TEST - Ukl√°d√°m vzpom√≠nku, ƒçtu ji zpƒõt po ƒçase
2. RECONSTRUCTION TEST - Kvalita rekonstrukce z pamƒõti
3. INTERFERENCE TEST - Prol√≠n√°n√≠ nesouvisej√≠c√≠ch vzpom√≠nek
4. CAPACITY TEST - Kolik DISTINKTN√çCH vzpom√≠nek lze ulo≈æit
5. CONSOLIDATION TEST - P≈ôe≈æ√≠vaj√≠ vzpom√≠nky konsolidaci STM‚ÜíLTM?

V√Ωstupy:
- Kvantitativn√≠ sk√≥re pro ka≈æd√Ω test
- Vizualizace pamƒõ≈•ov√©ho prostoru
- Doporuƒçen√≠ pro ladƒõn√≠
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import torch
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Tuple
from dataclasses import dataclass
from tqdm import tqdm
import matplotlib.pyplot as plt
import json

from cognitive_memory import (
    MemoryConfig,
    Terrain3D,
    MemoryCenters,
    MemoryWriter,
    SleepConsolidator,
    AutomaticConsolidator,
)


@dataclass
class MemoryItem:
    """Jedna vzpom√≠nka pro testov√°n√≠."""
    id: int
    key: torch.Tensor       # Unik√°tn√≠ kl√≠ƒç [d_model]
    value: torch.Tensor     # Oƒçek√°van√° hodnota [d_value]
    emotion: torch.Tensor   # Emoƒçn√≠ kontext [4]
    topic_id: int           # T√©ma/cluster
    timestamp: int          # Kdy byla ulo≈æena


@dataclass
class RetrievalResult:
    """V√Ωsledek vybaven√≠ vzpom√≠nky."""
    query_id: int
    retrieved_value: torch.Tensor
    expected_value: torch.Tensor
    similarity: float       # Cosine similarity
    exact_match: bool       # Nad prahem
    interference_score: float  # Jak moc se m√≠chaj√≠ jin√° t√©mata


class MemoryQualityTester:
    """
    Komplexn√≠ tester kvality pamƒõti.
    """
    
    def __init__(
        self,
        config: MemoryConfig = None,
        device: str = "cpu"
    ):
        self.config = config or MemoryConfig()
        self.device = device
        
        # Inicializace pamƒõ≈•ov√Ωch komponent
        self._init_memory()
        
        # √ölo≈æi≈°tƒõ vzpom√≠nek pro testov√°n√≠
        self.stored_memories: List[MemoryItem] = []
        self.retrieval_results: List[RetrievalResult] = []
        
    def _init_memory(self):
        """Inicializuje pamƒõ≈•ov√© komponenty."""
        config = self.config
        
        self.ltm_centers = MemoryCenters(
            n_centers=config.n_ltm_centers,
            d_key=config.d_memory_key,
            d_value=config.d_memory_value,
            sigma_read=config.ltm_sigma_read,
            sigma_write=config.ltm_sigma_write,
            leak=config.ltm_leak,
            device=self.device
        )
        
        self.stm_centers = MemoryCenters(
            n_centers=config.n_stm_centers,
            d_key=config.d_stm_key,
            d_value=config.d_memory_value,
            sigma_read=config.stm_sigma_read,
            sigma_write=config.stm_sigma_write,
            leak=config.stm_leak,
            device=self.device
        )
        
        self.ltm_terrain = Terrain3D(config.terrain_resolution, device=self.device)
        self.stm_terrain = Terrain3D(config.terrain_resolution, device=self.device)
        
        self.writer = MemoryWriter(
            d_model=config.d_model,
            d_ltm_key=config.d_memory_key,
            d_stm_key=config.d_stm_key,
            d_value=config.d_memory_value,
            write_strength_base=config.write_strength_base,
            write_bias=config.write_bias,
        )
        
        self.consolidator = AutomaticConsolidator(
            SleepConsolidator(
                d_stm_key=config.d_stm_key,
                d_ltm_key=config.d_memory_key,
                fatigue_threshold=config.fatigue_threshold,
                consolidation_kappa=config.consolidation_kappa,
            ),
            min_interval=50
        )
    
    def create_distinct_memory(
        self,
        topic_id: int,
        memory_id: int,
        d_model: int = 256
    ) -> MemoryItem:
        """
        Vytvo≈ô√≠ DISTINKTN√ç vzpom√≠nku s unik√°tn√≠m vzorem.
        
        Kl√≠ƒç a hodnota jsou korelov√°ny, aby bylo mo≈æn√© testovat rekonstrukci.
        """
        # Unik√°tn√≠ seed pro reprodukovatelnost
        torch.manual_seed(topic_id * 1000 + memory_id)
        
        # Kl√≠ƒç m√° strukturu: topic_base + memory_specific
        topic_base = torch.randn(d_model) 
        topic_base = topic_base / topic_base.norm()
        
        memory_specific = torch.randn(d_model) * 0.3
        key = F.normalize(topic_base + memory_specific, dim=-1)
        
        # Hodnota je ODVODITELN√Å z kl√≠ƒçe (pro testov√°n√≠ rekonstrukce)
        # Pou≈æijeme deterministickou transformaci
        value_seed = (key[:self.config.d_memory_value] + key[-self.config.d_memory_value:]) / 2
        value = F.normalize(value_seed, dim=-1)
        
        # Emoce koreluj√≠ s t√©matem
        base_emotion = torch.ones(4)
        base_emotion[topic_id % 4] += 0.5  # Jedno dominantn√≠
        emotion = torch.clamp(base_emotion + torch.randn(4) * 0.1, 0.5, 2.0)
        
        return MemoryItem(
            id=memory_id,
            key=key,
            value=value,
            emotion=emotion,
            topic_id=topic_id,
            timestamp=0
        )
    
    def store_memory(self, memory: MemoryItem, timestamp: int):
        """
        Ulo≈æ√≠ vzpom√≠nku do pamƒõti.
        """
        memory.timestamp = timestamp
        
        # P≈ôevod na batch form√°t
        hidden_states = memory.key.unsqueeze(0).unsqueeze(0).to(self.device)  # [1, 1, d_model]
        
        # !!! OPRAVA LOGIKY TESTU !!!
        # MemoryWriter ignoruje p≈Øvodn√≠ memory.value a m√≠sto toho generuje 
        # hodnotu k ulo≈æen√≠ projekc√≠ z hidden_states.
        # Mus√≠me aktualizovat na≈°e oƒçek√°v√°n√≠ (memory.value), aby odpov√≠dalo tomu,
        # co MemoryWriter skuteƒçnƒõ ulo≈æ√≠.
        
        with torch.no_grad():
            # Z√≠sk√°me projekci, kterou prov√°d√≠ writer internƒõ
            projected_value = self.writer.proj.project_to_value(hidden_states) # [1, 1, d_value]
            
            # Aktualizujeme ground truth pro test
            memory.value = projected_value.squeeze(0).squeeze(0).detach()
            
            # Pozn√°mka: Pokud by MemoryWriter dƒõlal dal≈°√≠ normalizaci, mƒõli bychom ji zde tak√© prov√©st.
            # Pro cosine similarity (v retrieve_memory) na ≈°k√°le nez√°le≈æ√≠.
        
        # S√≠la z√°pisu - vysok√° pro testov√°n√≠
        surprise = torch.tensor([[0.8]], device=self.device)
        
        stats = self.writer.write_to_memory(
            hidden_states=hidden_states,
            emotions=memory.emotion.to(self.device),
            ltm_centers=self.ltm_centers,
            stm_centers=self.stm_centers,
            ltm_terrain=self.ltm_terrain,
            stm_terrain=self.stm_terrain,
            surprise=surprise
        )
        
        self.stored_memories.append(memory)
        
        return stats
    
    def retrieve_memory(self, query_key: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, float]:
        """
        Vybaven√≠ vzpom√≠nky z pamƒõti.
        
        Returns:
            (retrieved_value, retrieved_emotion, confidence)
        """
        # Projekce do LTM key space - OPRAVA: spr√°vn√Ω form√°t
        query_batch = query_key.unsqueeze(0).unsqueeze(0).to(self.device)  # [1, 1, d_model]
        q_ltm = self.writer.proj.project_to_ltm(query_batch)  # [1, 1, d_ltm_key]
        
        # ƒåten√≠ z LTM
        r_V, r_E, weights, indices = self.ltm_centers.read(
            q_ltm,  # [1, 1, d_key]
            top_k=8
        )
        
        # Confidence = suma vah (ƒç√≠m vy≈°≈°√≠, t√≠m jistƒõj≈°√≠ vybaven√≠)
        confidence = weights.max().item() if weights.shape[-1] > 0 else 0.0
        
        return r_V.squeeze(0).squeeze(0), r_E.squeeze(0).squeeze(0), confidence
    
    def test_retention(
        self,
        n_memories: int = 50,
        n_topics: int = 10,
        delay_steps: int = 100
    ) -> Dict:
        """
        TEST 1: RETENTION
        
        Ulo≈æ√≠ vzpom√≠nky, poƒçk√°, pak je zkus√≠ vybavit.
        Mƒõ≈ô√≠ kolik z nich je st√°le dostupn√Ωch.
        """
        print("\n" + "="*60)
        print("TEST 1: RETENTION (Uchov√°n√≠ vzpom√≠nek)")
        print("="*60)
        
        # Reset pamƒõti
        self._init_memory()
        self.stored_memories = []
        
        # 1. Ulo≈æ vzpom√≠nky
        print(f"\nüìù Ukl√°d√°m {n_memories} vzpom√≠nek ({n_topics} t√©mat)...")
        
        for i in tqdm(range(n_memories), desc="Storing"):
            topic_id = i % n_topics
            memory = self.create_distinct_memory(topic_id, i, self.config.d_model)
            self.store_memory(memory, timestamp=i)
            
            # Homeost√°za po ka≈æd√©m z√°pisu
            self.ltm_centers.homeostasis_step()
            self.stm_centers.homeostasis_step()
        
        print(f"   LTM centers: {self.ltm_centers.get_n_active()}")
        print(f"   STM centers: {self.stm_centers.get_n_active()}")
        
        # 2. Simuluj ƒças (homeost√°za bez z√°pis≈Ø)
        print(f"\n‚è≥ Simuluji {delay_steps} krok≈Ø bez z√°pis≈Ø...")
        for _ in tqdm(range(delay_steps), desc="Time passing"):
            self.ltm_centers.homeostasis_step()
            self.stm_centers.homeostasis_step()
        
        # 3. Zkus vybavit ka≈ædou vzpom√≠nku
        print(f"\nüîç Vybavuji vzpom√≠nky...")
        
        retrievals = []
        for memory in tqdm(self.stored_memories, desc="Retrieving"):
            r_V, r_E, confidence = self.retrieve_memory(memory.key)
            
            # Mƒõ≈ô podobnost s oƒçek√°vanou hodnotou
            if r_V.norm() > 1e-6 and memory.value.norm() > 1e-6:
                similarity = F.cosine_similarity(
                    r_V.unsqueeze(0), 
                    memory.value.to(self.device).unsqueeze(0)
                ).item()
            else:
                similarity = 0.0
            
            retrievals.append({
                "memory_id": memory.id,
                "topic_id": memory.topic_id,
                "similarity": similarity,
                "confidence": confidence,
                "age": delay_steps + (n_memories - memory.id)
            })
        
        # 4. Anal√Ωza v√Ωsledk≈Ø
        similarities = [r["similarity"] for r in retrievals]
        confidences = [r["confidence"] for r in retrievals]
        
        # Pr√°h pro "√∫spƒõ≈°n√© vybaven√≠"
        threshold = 0.5
        successful = sum(1 for s in similarities if s > threshold)
        
        results = {
            "n_memories": n_memories,
            "n_topics": n_topics,
            "delay_steps": delay_steps,
            "retention_rate": successful / n_memories,
            "avg_similarity": np.mean(similarities),
            "std_similarity": np.std(similarities),
            "avg_confidence": np.mean(confidences),
            "ltm_centers_final": self.ltm_centers.get_n_active(),
            "stm_centers_final": self.stm_centers.get_n_active(),
            "retrievals": retrievals
        }
        
        print(f"\nüìä V√ùSLEDKY RETENTION TESTU:")
        print(f"   Retention rate: {results['retention_rate']:.1%}")
        print(f"   Pr≈Ømƒõrn√° podobnost: {results['avg_similarity']:.3f}")
        print(f"   Pr≈Ømƒõrn√° confidence: {results['avg_confidence']:.3f}")
        print(f"   LTM centers: {results['ltm_centers_final']}")
        
        return results
    
    def test_interference(
        self,
        n_topics: int = 10,
        memories_per_topic: int = 10
    ) -> Dict:
        """
        TEST 2: INTERFERENCE
        
        Mƒõ≈ô√≠, jak moc se vzpom√≠nky z r≈Øzn√Ωch t√©mat prol√≠naj√≠.
        """
        print("\n" + "="*60)
        print("TEST 2: INTERFERENCE (Prol√≠n√°n√≠ vzpom√≠nek)")
        print("="*60)
        
        # Reset pamƒõti
        self._init_memory()
        self.stored_memories = []
        
        # Ulo≈æ vzpom√≠nky ze v≈°ech t√©mat
        print(f"\nüìù Ukl√°d√°m {n_topics * memories_per_topic} vzpom√≠nek...")
        
        memory_id = 0
        for topic in range(n_topics):
            for _ in range(memories_per_topic):
                memory = self.create_distinct_memory(topic, memory_id, self.config.d_model)
                self.store_memory(memory, timestamp=memory_id)
                memory_id += 1
        
        # Mƒõ≈ô interference: dotaz na t√©ma A, kolik z v√Ωsledku je z jin√Ωch t√©mat
        print(f"\nüîç Mƒõ≈ô√≠m interference...")
        
        interference_scores = []
        
        for topic in range(n_topics):
            # Vyber reprezentativn√≠ vzpom√≠nku z t√©matu
            topic_memories = [m for m in self.stored_memories if m.topic_id == topic]
            query_memory = topic_memories[0]
            
            # Projekce dotazu
            q_ltm = self.writer.proj.project_to_ltm(
                query_memory.key.unsqueeze(0).unsqueeze(0)
            ).squeeze(0)
            
            # Najdi nejbli≈æ≈°√≠ centra
            weights, indices = self.ltm_centers.compute_rbf_weights(
                q_ltm.unsqueeze(0),
                top_k=16,
                normalize=True
            )
            
            if weights.shape[-1] == 0:
                interference_scores.append(0.0)
                continue
            
            # Zjisti, kolik center "nepat≈ô√≠" k tomuto t√©matu
            # (Toto je aproximace - nem√°me p≈ô√≠m√© mapov√°n√≠ center na t√©mata)
            total_weight = weights.sum().item()
            interference_scores.append(1.0 - total_weight)  # Vy≈°≈°√≠ = v√≠ce interference
        
        results = {
            "n_topics": n_topics,
            "memories_per_topic": memories_per_topic,
            "avg_interference": np.mean(interference_scores),
            "max_interference": np.max(interference_scores),
            "ltm_centers": self.ltm_centers.get_n_active(),
            "centers_per_topic": self.ltm_centers.get_n_active() / n_topics
        }
        
        print(f"\nüìä V√ùSLEDKY INTERFERENCE TESTU:")
        print(f"   Pr≈Ømƒõrn√° interference: {results['avg_interference']:.3f}")
        print(f"   Maxim√°ln√≠ interference: {results['max_interference']:.3f}")
        print(f"   LTM centra: {results['ltm_centers']}")
        print(f"   Centra/t√©ma: {results['centers_per_topic']:.1f}")
        
        return results
    
    def test_capacity(
        self,
        max_memories: int = 200,
        similarity_threshold: float = 0.3
    ) -> Dict:
        """
        TEST 3: CAPACITY
        
        Kolik DISTINKTN√çCH vzpom√≠nek lze ulo≈æit p≈ôed degradac√≠?
        """
        print("\n" + "="*60)
        print("TEST 3: CAPACITY (Kapacita pamƒõti)")
        print("="*60)
        
        # Reset pamƒõti
        self._init_memory()
        self.stored_memories = []
        
        print(f"\nüìù Postupnƒõ ukl√°d√°m a≈æ {max_memories} vzpom√≠nek...")
        
        capacity_curve = []
        degradation_point = None
        
        for i in tqdm(range(max_memories), desc="Testing capacity"):
            # Vytvo≈ô a ulo≈æ vzpom√≠nku (ka≈æd√° z jin√©ho "mini-t√©matu")
            memory = self.create_distinct_memory(topic_id=i, memory_id=i, d_model=self.config.d_model)
            self.store_memory(memory, timestamp=i)
            
            # Homeost√°za
            self.ltm_centers.homeostasis_step()
            
            # Ka≈æd√Ωch 10 vzpom√≠nek zkontroluj retention
            if (i + 1) % 10 == 0:
                # Zkus vybavit n√°hodn√Ω vzorek
                sample_size = min(10, len(self.stored_memories))
                sample_indices = np.random.choice(len(self.stored_memories), sample_size, replace=False)
                
                similarities = []
                for idx in sample_indices:
                    mem = self.stored_memories[idx]
                    r_V, _, _ = self.retrieve_memory(mem.key)
                    
                    if r_V.norm() > 1e-6:
                        sim = F.cosine_similarity(
                            r_V.unsqueeze(0),
                            mem.value.to(self.device).unsqueeze(0)
                        ).item()
                        similarities.append(sim)
                
                avg_sim = np.mean(similarities) if similarities else 0.0
                
                capacity_curve.append({
                    "n_memories": i + 1,
                    "avg_similarity": avg_sim,
                    "ltm_centers": self.ltm_centers.get_n_active(),
                    "stm_centers": self.stm_centers.get_n_active()
                })
                
                # Detekce degradace
                if degradation_point is None and avg_sim < similarity_threshold:
                    degradation_point = i + 1
        
        results = {
            "max_tested": max_memories,
            "degradation_point": degradation_point or max_memories,
            "final_ltm_centers": self.ltm_centers.get_n_active(),
            "final_stm_centers": self.stm_centers.get_n_active(),
            "capacity_curve": capacity_curve
        }
        
        print(f"\nüìä V√ùSLEDKY CAPACITY TESTU:")
        print(f"   Bod degradace: {results['degradation_point']} vzpom√≠nek")
        print(f"   Fin√°ln√≠ LTM centra: {results['final_ltm_centers']}")
        print(f"   Fin√°ln√≠ STM centra: {results['final_stm_centers']}")
        
        return results
    
    def test_consolidation_survival(
        self,
        n_memories: int = 30,
        n_consolidations: int = 5
    ) -> Dict:
        """
        TEST 4: CONSOLIDATION SURVIVAL
        
        P≈ôe≈æ√≠vaj√≠ vzpom√≠nky konsolidaci STM‚ÜíLTM?
        """
        print("\n" + "="*60)
        print("TEST 4: CONSOLIDATION SURVIVAL")
        print("="*60)
        
        # Reset pamƒõti
        self._init_memory()
        self.stored_memories = []
        
        # Ulo≈æ vzpom√≠nky
        print(f"\nüìù Ukl√°d√°m {n_memories} vzpom√≠nek...")
        
        for i in range(n_memories):
            memory = self.create_distinct_memory(i % 5, i, self.config.d_model)
            self.store_memory(memory, timestamp=i)
        
        # Mƒõ≈ôen√≠ p≈ôed konsolidac√≠
        pre_results = self._measure_retrieval_quality()
        print(f"   P≈òED konsolidac√≠: avg_sim={pre_results['avg_similarity']:.3f}")
        
        # Proveƒè konsolidace
        print(f"\nüí§ Prov√°d√≠m {n_consolidations} konsolidac√≠...")
        
        for _ in range(n_consolidations):
            # Vynut√≠ konsolidaci (nastavit fatigue nad threshold)
            self.consolidator.consolidator.fatigue = torch.tensor(
                self.config.fatigue_threshold + 1.0
            )
            
            self.consolidator.consolidator.consolidate(
                self.stm_centers,
                self.ltm_centers,
                self.stm_terrain,
                self.ltm_terrain
            )
        
        # Mƒõ≈ôen√≠ po konsolidaci
        post_results = self._measure_retrieval_quality()
        print(f"   PO konsolidaci: avg_sim={post_results['avg_similarity']:.3f}")
        
        results = {
            "n_memories": n_memories,
            "n_consolidations": n_consolidations,
            "pre_consolidation": pre_results,
            "post_consolidation": post_results,
            "survival_rate": post_results['avg_similarity'] / max(pre_results['avg_similarity'], 0.01),
            "ltm_centers_gained": post_results['ltm_centers'] - pre_results['ltm_centers']
        }
        
        print(f"\nüìä V√ùSLEDKY CONSOLIDATION TESTU:")
        print(f"   Survival rate: {results['survival_rate']:.1%}")
        print(f"   LTM centra: {pre_results['ltm_centers']} ‚Üí {post_results['ltm_centers']}")
        
        return results
    
    def _measure_retrieval_quality(self) -> Dict:
        """Pomocn√° metoda pro mƒõ≈ôen√≠ kvality vybaven√≠."""
        similarities = []
        
        for memory in self.stored_memories:
            r_V, _, _ = self.retrieve_memory(memory.key)
            
            if r_V.norm() > 1e-6:
                sim = F.cosine_similarity(
                    r_V.unsqueeze(0),
                    memory.value.to(self.device).unsqueeze(0)
                ).item()
                similarities.append(sim)
        
        return {
            "avg_similarity": np.mean(similarities) if similarities else 0.0,
            "std_similarity": np.std(similarities) if similarities else 0.0,
            "ltm_centers": self.ltm_centers.get_n_active(),
            "stm_centers": self.stm_centers.get_n_active()
        }
    
    def run_full_suite(self) -> Dict:
        """
        Spust√≠ v≈°echny testy a vytvo≈ô√≠ souhrnn√Ω report.
        """
        print("\n" + "="*70)
        print("üß† COGNITIVE MEMORY - QUALITY TEST SUITE")
        print("="*70)
        
        results = {}
        
        # Test 1: Retention
        results["retention"] = self.test_retention(
            n_memories=50,
            n_topics=10,
            delay_steps=100
        )
        
        # Test 2: Interference
        results["interference"] = self.test_interference(
            n_topics=10,
            memories_per_topic=10
        )
        
        # Test 3: Capacity
        results["capacity"] = self.test_capacity(
            max_memories=100,
            similarity_threshold=0.3
        )
        
        # Test 4: Consolidation
        results["consolidation"] = self.test_consolidation_survival(
            n_memories=30,
            n_consolidations=3
        )
        
        # Souhrnn√© hodnocen√≠
        print("\n" + "="*70)
        print("üìã SOUHRNN√â HODNOCEN√ç")
        print("="*70)
        
        scores = {
            "retention": results["retention"]["retention_rate"],
            "interference": 1.0 - results["interference"]["avg_interference"],
            "capacity": min(1.0, results["capacity"]["degradation_point"] / 100),
            "consolidation": results["consolidation"]["survival_rate"]
        }
        
        overall = np.mean(list(scores.values()))
        
        print(f"\n   Retention Score:     {scores['retention']:.1%}")
        print(f"   Anti-Interference:   {scores['interference']:.1%}")
        print(f"   Capacity Score:      {scores['capacity']:.1%}")
        print(f"   Consolidation Score: {scores['consolidation']:.1%}")
        print(f"\n   ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        print(f"   OVERALL SCORE:       {overall:.1%}")
        
        if overall > 0.7:
            print(f"\n   ‚úÖ Pamƒõ≈• funguje DOB≈òE")
        elif overall > 0.4:
            print(f"\n   ‚ö†Ô∏è  Pamƒõ≈• pot≈ôebuje LADƒöN√ç")
        else:
            print(f"\n   ‚ùå Pamƒõ≈• m√° V√Å≈ΩN√â PROBL√âMY")
        
        results["summary"] = {
            "scores": scores,
            "overall": overall
        }
        
        return results
    
    def save_results(self, results: Dict, path: str = "memory_quality_results.json"):
        """Ulo≈æ√≠ v√Ωsledky do JSON."""
        # Konverze non-serializovateln√Ωch typ≈Ø
        def convert(obj):
            if isinstance(obj, np.floating):
                return float(obj)
            if isinstance(obj, np.integer):
                return int(obj)
            if isinstance(obj, torch.Tensor):
                return obj.tolist()
            if isinstance(obj, dict):
                return {k: convert(v) for k, v in obj.items()}
            if isinstance(obj, list):
                return [convert(x) for x in obj]
            return obj
        
        with open(path, 'w') as f:
            json.dump(convert(results), f, indent=2)
        
        print(f"\n‚úì V√Ωsledky ulo≈æeny: {path}")


def main():
    """Entry point."""
    # Konfigurace optimalizovan√° pro testov√°n√≠
    config = MemoryConfig(
        d_model=256,
        n_ltm_centers=512,
        n_stm_centers=128,
        terrain_resolution=24,
        
        # Vy≈°≈°√≠ plasticita pro lep≈°√≠ z√°pis
        write_strength_base=0.4,
        write_bias=-0.2,
        
        # Men≈°√≠ sigma = v√≠ce distinktn√≠ch center
        ltm_sigma_write=0.2,
        ltm_sigma_read=0.3,
        stm_sigma_write=0.15,
        stm_sigma_read=0.25,
        
        # Pomalej≈°√≠ decay pro lep≈°√≠ retention
        ltm_leak=1e-5,
        stm_leak=1e-4,
        
        # Ni≈æ≈°√≠ threshold pro consolidation testing
        fatigue_threshold=2.0,
        consolidation_kappa=0.8,
    )
    
    tester = MemoryQualityTester(config)
    results = tester.run_full_suite()
    tester.save_results(results)


if __name__ == "__main__":
    main()
