# ğŸ§  Cognitive Memory

**Biologically Inspired Persistent Memory System for Large Language Models**

[![License: CC BY-NC 4.0](https://img.shields.io/badge/License-CC%20BY--NC%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc/4.0/)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/pytorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

---

## ğŸŒŸ Overview

Cognitive Memory implements a **two-layer persistent memory architecture** for LLMs, inspired by biological memory systems:

| Biological Structure | System Component | Function |
|---------------------|------------------|----------|
| **Hippocampus** | STM (16D) | Fast encoding, limited capacity |
| **Neocortex** | LTM (64D) | Slow consolidation, long-term retention |
| **Sleep (SWS)** | Consolidation | Transfer memories from STM to LTM |

### âœ¨ Key Features

- ğŸ§¬ **Biologically Inspired**: Two-layer STM/LTM architecture with sleep-like consolidation
- ğŸŒŠ **3D Diffusion Terrains**: Spatial memory representation with homeostasis
- ğŸ¯ **RBF Kernel Operations**: Smooth, localized memory read/write
- ğŸ’­ **Emotional Coloring**: 4D emotional vectors (dopamine, serotonin, cortisol, oxytocin)
- âš¡ **Transformer Integration**: Memory Attention blocks with gating mechanism
- ğŸ“¦ **Persistent Storage**: Save/load complete memory state
- ğŸ”§ **Configurable**: Coefficients calibrated for yearly operation

---

## ğŸ“¦ Installation

### From Source

```bash
git clone https://github.com/OpenTechLab/cognitive-memory.git
cd cognitive-memory
pip install -e .
```

### Requirements

```bash
pip install torch>=2.0.0 numpy>=1.20.0 scipy>=1.7.0
```

---

## ğŸš€ Quick Start

```python
import torch
from cognitive_memory import CognitiveMemorySystem, MemoryConfig

# Create memory system
config = MemoryConfig(d_model=256, n_ltm_centers=1024)
memory = CognitiveMemorySystem(config, device="cuda")

# Read from memory during inference
hidden_states = torch.randn(1, 32, 256)
memory_context, emotions, gate = memory.read(hidden_states, layer_idx=7)

# Write to memory after generation  
segment_states = torch.randn(5, 256)
memory.write(segment_states=segment_states, emotions=torch.randn(5, 4))

# Automatic consolidation (STM â†’ LTM)
if memory.should_consolidate():
    stats = memory.consolidate()
    
# Persist memory state
memory.save("memory_state.pt")
```

### Transformer Integration

```python
from cognitive_memory import MemoryBlock

class TransformerBlockWithMemory(nn.Module):
    def __init__(self, d_model, config):
        super().__init__()
        self.attn = Attention(...)
        self.memory_block = MemoryBlock(config)
        self.ffn = FeedForward(...)
    
    def forward(self, x, memory_state):
        y = x + self.attn(self.ln1(x))
        
        if memory_state is not None:
            m, emotions, gate = self.memory_block(self.ln_memory(y), memory_state)
            y = y + gate * m  # Gated residual
        
        return y + self.ffn(self.ln2(y))
```

---

## ğŸ“‚ Project Structure

```
cognitive-memory/
â”œâ”€â”€ README.md                  # This file (English)
â”œâ”€â”€ README_CZ.md              # Czech documentation
â”œâ”€â”€ LICENSE                    # CC BY-NC 4.0
â”œâ”€â”€ setup.py                   # Installation script
â”œâ”€â”€ requirements.txt           # Dependencies
â”‚
â”œâ”€â”€ cognitive_memory/          # Main package
â”‚   â”œâ”€â”€ __init__.py           # Public API
â”‚   â”œâ”€â”€ config.py             # Configuration
â”‚   â”œâ”€â”€ memory_centers.py     # RBF kernel centers
â”‚   â”œâ”€â”€ terrain_3d.py         # 3D diffusion terrains
â”‚   â”œâ”€â”€ memory_block.py       # Transformer integration
â”‚   â”œâ”€â”€ memory_attention.py   # Memory attention mechanism
â”‚   â”œâ”€â”€ terrain_prior.py      # 3Dâ†’64D query bias
â”‚   â”œâ”€â”€ writer.py             # Memory writing
â”‚   â”œâ”€â”€ consolidation.py      # Sleep consolidation
â”‚   â”œâ”€â”€ projections.py        # Dimension projections
â”‚   â””â”€â”€ persistence.py        # State save/load
â”‚
â””â”€â”€ tests/                     # Validation & benchmarks
    â”œâ”€â”€ README.md             # Test documentation
    â”œâ”€â”€ test_memory_fundamentals.py
    â”œâ”€â”€ stress_test_memory.py
    â”œâ”€â”€ ablation_study.py
    â””â”€â”€ visualize_*.py
```

---

## ğŸ“ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         COGNITIVE MEMORY                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   LTM (64D)          â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤   STM (16D)          â”‚      â”‚
â”‚  â”‚   half-life ~1yr     â”‚  sleep  â”‚   half-life ~weeks   â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚      â”‚
â”‚  â”‚  â”‚ RBF Centers   â”‚   â”‚         â”‚  â”‚ RBF Centers   â”‚   â”‚      â”‚
â”‚  â”‚  â”‚ K,V,h,e       â”‚   â”‚         â”‚  â”‚ K,V,h,e       â”‚   â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚      â”‚
â”‚  â”‚  â”‚ 3D Terrain    â”‚   â”‚         â”‚  â”‚ 3D Terrain    â”‚   â”‚      â”‚
â”‚  â”‚  â”‚ (diffusion)   â”‚   â”‚         â”‚  â”‚ (fast diff.)  â”‚   â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                              â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              TransformerBlock Memory Attention            â”‚   â”‚
â”‚  â”‚  Y = X + SA(LN(X))                                        â”‚   â”‚
â”‚  â”‚  M = MemAttn(LN(Y))  â† TerrainPrior + RBF read            â”‚   â”‚
â”‚  â”‚  Y' = Y + g âŠ™ W_m M  â† Gated memory injection             â”‚   â”‚
â”‚  â”‚  X_out = Y' + MLP(LN(Y'))                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Configuration

Default coefficients are calibrated for **~50 interactions/day** = **~18,250 steps/year**.

```python
from cognitive_memory import MemoryConfig

config = MemoryConfig(
    # Dimensions
    d_model=256,
    d_memory_key=64,        # LTM key dimension
    d_stm_key=16,           # STM key dimension
    
    # LTM (half-life ~1 year)
    ltm_leak=3.8e-5,
    ltm_sigma_read=0.5,
    ltm_sigma_write=0.15,   # Sharp traces
    
    # STM (half-life days-weeks)  
    stm_leak=5e-3,
    
    # Consolidation
    fatigue_threshold=5.0,
    consolidation_kappa=0.8,
)
```

---

## ğŸ§ª Testing & Validation

```bash
# Basic tests (~3 sec)
python tests/test_memory_fundamentals.py

# Stress test (~5 min, 9000 interactions)
python tests/stress_test_memory.py

# Complete suite with visualizations
python tests/run_full_memory_suite.py
```

### Validated Metrics (2026-01-14)

| Metric | Value | Status |
|--------|-------|--------|
| LTM Active Centers | 459 | âœ… Excellent |
| Retention (1000 steps) | 100% | âœ… |
| Self-Reconstruction | 0.92 | âœ… Very good |
| Retrieval Accuracy | 100% | âœ… |

---

## ğŸ“š Documentation

- **[cognitive_memory/README.md](cognitive_memory/README.md)** - Detailed API documentation
- **[tests/README.md](tests/README.md)** - Testing framework guide
- **Mathematical description** included in package README

---

## ğŸ“„ License

**CC BY-NC 4.0** (Creative Commons Attribution-NonCommercial 4.0)

âœ… Allowed: Research, education, modification, distribution (with attribution)  
âŒ Prohibited: Commercial use without license

For commercial licensing: **opentechlab@opentechlab.cz**

---

## ğŸ¤ Citation

```bibtex
@software{cognitive_memory_2026,
  author = {Seidl, Michal},
  title = {Cognitive Memory: Biologically Inspired Persistent Memory for LLMs},
  year = {2026},
  publisher = {OpenTechLab Jablonec nad Nisou},
  version = {2.0-beta},
  url = {https://github.com/OpenTechLab/cognitive-memory}
}
```

---

## ğŸ“¬ Contact

- **Email**: vyvoj@opentechlab.cz
- **Web**: [www.opentechlab.cz](https://www.opentechlab.cz)
- **Project**: BioCortexAI Framework

---

**Framework:** BioCortexAI v2.0-beta  
**Author:** Michal Seidl, OpenTechLab Jablonec nad Nisou s.r.o.  
**Status:** âœ… Production-ready
